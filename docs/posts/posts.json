[
  {
    "path": "posts/2021-02-24-heat-map-of-california-oil-spills/",
    "title": "Heat Map of California Oil Spills",
    "description": "I determined the counties with the most oil spills using the California Department of Fish and Wildlife 2008 Oil Spill Incident Tracking and county maps from the Census Bureau.",
    "author": [],
    "date": "2021-03-13",
    "categories": [],
    "contents": "\r\n\r\nShow code\r\nknitr::opts_chunk$set(echo = FALSE)\r\n#set up\r\nlibrary(tidyverse)\r\nlibrary(here)\r\nlibrary(sf)\r\nlibrary(janitor)\r\nlibrary(lubridate)\r\n\r\n\r\n#read in .shp file\r\nca_counties <- read_sf(here( \"_posts\",\"2021-02-24-heat-map-of-california-oil-spills\", \"data\",\"ca_counties\", \"CA_Counties_TIGER2016.shp\"))\r\nca_subset <- ca_counties %>% \r\n  select(NAME, ALAND) %>% \r\n  rename(county_name = NAME, land_area = ALAND)\r\nca_oilspill <- read_sf(here(\"_posts\",\"2021-02-24-heat-map-of-california-oil-spills\", \"data\", \"ds394.shp\")) %>% \r\n  clean_names()\r\n\r\n#Check CRS and plot info\r\n#ca_subset %>% st_crs()\r\n#ca_oilspill %>%  st_crs()\r\n\r\n#change ca_oilspill to WGS 84\r\nca_oilspill <-  st_transform(ca_oilspill, 3857)\r\n\r\n#join county and oilspill data to one\r\nca_county_oilspill <- ca_subset %>% \r\n  st_join(ca_oilspill)\r\n\r\n\r\n\r\n\r\nShow code\r\n#counts data \r\noilspill_counts <- ca_county_oilspill %>% \r\n  count(county_name)\r\n#map it! But is not interactive map \r\nggplot(data = oilspill_counts) +\r\n  geom_sf(aes(fill = n), color = \"white\", size = 0.1) +\r\n  scale_fill_gradientn(colors = c(\"lightgray\", \"blue\", \"navy\"))+\r\n  theme_minimal() +\r\n  labs(fill = \"Number of oil spill incidents\", title = \"2008 California Oil Spill County Heat Map\") \r\n\r\n\r\n\r\n\r\nSummary:\r\nThis project was my first introduction to R’s geospatial capabilities. 2008 oil spill data from the California Department of Fish and Wildlife was mapped onto county outlines provided by the US Census Bureau. The coordinate reference system for both was WGS 84. Using the data provided and the package “sf”, I found the counties with the most incidents in California and visualized it. It was a great learning experience to get data from different sources and visualize it on my own.\r\nCitations:\r\nCalifornia Department of Fish and Wildlife. (2009). Oil Spill Incident Tracking [ds394]. OSPR Incident Tracking Database System. https://map.dfg.ca.gov/metadata/ds0394.html#ID0EUGA\r\nUS Census Bureau, Department of Commerce. (2016). TIGER/Line Shapefile, 2016, state, California, Current County Subdivision State-based. Data.gov. https://catalog.data.gov/dataset/tiger-line-shapefile-2016-state-california-current-county-subdivision-state-based\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-02-24-heat-map-of-california-oil-spills/heat-map-of-california-oil-spills_files/figure-html5/unnamed-chunk-1-1.png",
    "last_modified": "2021-03-13T10:22:42-08:00",
    "input_file": "heat-map-of-california-oil-spills.utf8.md"
  },
  {
    "path": "posts/2021-03-12-worldev/",
    "title": "Finding Relationships Between World Vairables",
    "description": "For this study, I wanted to see if there are relationships between the world's tree canopy cover, mean annual temperature, cloudiness, and cropland cover. The data used in this study provided by zander_venter(https://www.kaggle.com/zanderventer/datasets) on Kaggle, who acquired the data through Google Earth Engine (https://earthengine.google.com/). Mean values for 243 countries were calculated at a reduction scale of 10 km. To determine the relationships between the variables, I performed a principal components analysis (PCA) and displayed the information on a biplot, where the two principle components visualized accounted for 77% of the variance in the data.",
    "author": [],
    "date": "2021-03-13",
    "categories": [],
    "contents": "\r\n\r\nShow code\r\nknitr::opts_chunk$set(echo = TRUE)\r\n\r\n#Set up section\r\nlibrary(tidyverse)\r\nlibrary(janitor)\r\nlibrary(palmerpenguins)\r\nlibrary(here)\r\n\r\n#for PCA\r\nlibrary(ggfortify)\r\n\r\n#For ggplot customization\r\nlibrary(readxl)\r\nlibrary(gghighlight)\r\nlibrary(lubridate)\r\nlibrary(plotly)\r\n\r\n#to make compound figures \r\nlibrary(patchwork)\r\n\r\n#read in .csv file\r\nworld_env_vars <- read_csv(here(\"_posts\", \"2021-03-12-worldev\", \"data\", \"world_env_vars.csv\"))\r\n\r\n\r\n\r\n\r\nShow code\r\n#Task 2 \r\n#create new columns with better variable names to make the graph more professional \r\nworld_env_vars <- world_env_vars %>% \r\n  mutate(\"Cropland Cover\" = cropland_cover, \r\n         \"Tree Canopy Cover\" = tree_canopy_cover,\r\n         \"Mean Annual Temperature\" = temp_mean_annual,\r\n         \"Cloudiness\" = cloudiness)\r\n#select variables that I want to include in my PCA biplot\r\nenv_vars_PCA <- world_env_vars %>%\r\n  select(\"Cropland Cover\", \"Tree Canopy Cover\", \"Mean Annual Temperature\", \"Cloudiness\") %>% \r\n  drop_na() %>% \r\n  scale() %>% #allows us to compare variables evenly\r\n  prcomp() #run PCA on data\r\n\r\n#needed to create PCA biplot\r\nenv_vars_complete <- world_env_vars %>% \r\n  drop_na(\"Cropland Cover\", \"Tree Canopy Cover\", \"Mean Annual Temperature\", \"Cloudiness\")\r\n#create pca biplot\r\nautoplot(env_vars_PCA,\r\n         data = env_vars_complete, \r\n         colour = 'black', \r\n         loadings = TRUE,\r\n         loadings.label = TRUE) + \r\n  theme_minimal() +\r\n  labs(title = \"Relationship between different envrionmental variables in the world\")\r\n\r\n\r\n\r\n\r\nFigure 1. Mean annual temperature, tree canopy cover, cloudiness, and cropland cover of different countries (each point represents a country) are plotted.\r\nSummary:\r\nThe principal components in this biplot capture approximately 77% of variance found in the data (PC1 = 42.91% and PC2 = 34.82%). Mean annual temperature has a strong negative correlation with cropland cover, both mean annual temperature and cropland cover have little to no correlation with either tree canopy cover or cloudiness, and tree canopy cover has a positive correlation with cloudiness.\r\nI think principal component analyses are incredibly interesting because I was able to determine and visualize the relationship between multiple variables. Although it might not account for 100% of the variance, PCAs will be a useful tool to use in the future.\r\nCitation:\r\nzander_venter. “Environmental Variables for World Countries.” Kaggle.com, 2018, www.kaggle.com/zanderventer/environmental-variables-for-world-countries. Accessed 24 Jan. 2021.\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-03-12-worldev/worldev_files/figure-html5/unnamed-chunk-2-1.png",
    "last_modified": "2021-03-13T10:23:17-08:00",
    "input_file": "worldev.utf8.md"
  },
  {
    "path": "posts/2021-03-12-monolake/",
    "title": "Water Levels in Mono Lake from 1850 - 2017",
    "description": "Here we take a look at the lake levels of Monolake from 1850 to 2017. Due to major changes by the Los Angeles Department of Water and Power, lake levels drastically decreased, which led to land bridge formations and increased water salinity.",
    "author": [],
    "date": "2021-03-13",
    "categories": [],
    "contents": "\r\n\r\nShow code\r\n#select data to use in figure\r\n\r\nlake_levels_fig <- lake_level_more_tidy %>% \r\n  select(\"year\", \"lake_level_asl\",\"stable_level\") \r\n  #make new data that includes data as numeric rather than characters\r\n  \r\nlake_levels_fig <- lake_levels_fig %>% \r\n  mutate(lake_levels_num = as.numeric(lake_levels_fig$lake_level_asl)) %>%\r\n  mutate(year_new = as.numeric(lake_levels_fig$year))\r\n\r\n#create figure using lake_levels_fig\r\nmono_lake_plot <- \r\n  ggplot(data = lake_levels_fig, aes(x = year_new, y = lake_levels_num)) + \r\n  scale_y_continuous(breaks = pretty_breaks(n=6)) +\r\n  coord_cartesian(ylim = c(6340, 6430))+\r\n  geom_line(size = 1.2, color = \"darkgreen\") +\r\n  labs(y = \"Lake Level (ft above sea level)\", x = \"Year\", title = \"Mono Lake Water Levels (1850-2017)\") +\r\n  annotate(geom = \"point\", x = 1994, y = 6374.6, shape = 16, size = 2, color = \"red\") +\r\n  annotate(geom = \"point\", x = 1941, y = 6417, shape = 16, size = 2, color = \"red\") +\r\n  geom_label(label = \"1994: State Waterboard Decision 1631\", x = 1970, y = 6368, color = \"black\", size = 2.175) +\r\n  geom_label(label = \"1941: Los Angeles Department of Water & Power (DWP)\", x = 1980, y = 6423, color = \"black\", size = 2.175) + geom_label(label = \"Decrease in availability of brine shrimp\", x = 1868, y = 6356, color = \"black\", size = 2.175)+\r\n  geom_label(label = \"Land bridge forms\", x = 1855, y = 6373, color = \"black\", size = 2.175)+\r\n  geom_hline(aes(yintercept=6360), color = \"lightcyan4\", size = 1) +\r\n  geom_hline(aes(yintercept=6377), color = \"goldenrod3\", size = 1) + \r\n  theme_minimal()\r\n\r\nmono_lake_plot\r\n\r\n\r\n\r\n\r\nSummary\r\nMono Lake water levels started drastically decreasing after the Los Angeles Department of Water and Power (DWP) started diverting water in 1941. When the water level reaches 6377 ft (above sea level), land bridges begin to form between the mainland and islands (gold line), allowing predators to access major bird nesting sites. If water levels fall to a lake level of 6360 ft (grey line), the salinity of the water becomes so high that brine shrimp populations decrease; this decrease would begin affecting bird species (e.g. eared grebe and California gulls) that rely on them. However, in 1994, the State Water Board set a lake level of 6392 feet, required permanent streamflows for Mono Basin streams, and ordered DWP to restore streams. I used the annotate(), geom_label(), and geom_hline to customize the figure and display more information about the actual and predicted effects of decreased water levels.\r\nCitation\r\nMono Basin Clearinghouse. (2020). Mono basin Clearinghouse: Building a digital library for better resource management. Retrieved December 12, 2020, from https://www.monobasinresearch.org/\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-03-12-monolake/monolake_files/figure-html5/unnamed-chunk-1-1.png",
    "last_modified": "2021-03-13T10:23:53-08:00",
    "input_file": "monolake.utf8.md"
  },
  {
    "path": "posts/2021-03-09-lotr/",
    "title": "Wordcloud of The Two Towers by J.R.R.",
    "description": "I took a pdf of The Two Towers by J.R.R. Tolken, found the top 100 words used, excluding common words such as \"the\" or \"a\", and visualized it in a wordcloud. I also added Smeagol in the background because he is adorable when he's not Gollum.",
    "author": [],
    "date": "2021-03-13",
    "categories": [],
    "contents": "\r\n\r\nShow code\r\n#put text into tidy data frame with each individual line having its own line in the data frame\r\n\r\nTT_tidy <- data.frame(TT_text) %>% \r\n  mutate(text_full = str_split(TT_text, pattern = \"\\\\n\")) %>% \r\n  unnest(text_full) %>% \r\n  mutate(text_full = str_trim(text_full))\r\n\r\n# start at chapter 1 and start identifying chapters within books \r\n\r\nTT_df <- TT_tidy %>% \r\n  slice(- (1:9)) %>% \r\n  mutate(chapter = case_when(\r\n    str_detect(text_full, pattern = \"Chapter\") ~ text_full,\r\n    TRUE ~ NA_character_\r\n  )) %>% \r\n  fill(chapter) %>% \r\n  separate(col = chapter, into = c(\"chap\", \"num\"), sep = \" \") %>% \r\n  mutate(Chapter = as.numeric(num))\r\n\r\n#get every word into its own row\r\nTT_tokens <- TT_df %>% \r\n  unnest_tokens(word, text_full) %>% \r\n  dplyr::select(-TT_text)\r\n\r\nTT_nonstop_words <- TT_tokens %>% \r\n  anti_join(stop_words)\r\n\r\n# ^^ with stop words\r\n# remove all stop words in all of the books\r\nnonstop_counts_TT <- TT_nonstop_words %>% \r\n  count(Chapter, word)\r\n\r\n\r\n#take top 5 words per chapter for TT\r\nTT_top5 <- nonstop_counts_TT %>% \r\n  group_by(Chapter) %>% \r\n  arrange (-n) %>% \r\n  slice(1:5)\r\n\r\n\r\n\r\n\r\nShow code\r\n# get counts for whole book of TT\r\nTT_book_counts <- TT_nonstop_words %>% \r\n  count(word)\r\n#get top 100 words from TT\r\nTT_top100 <- TT_book_counts %>% \r\n  arrange (-n) %>% \r\n  slice(1:100)\r\n\r\n#word cloud for whole TT book\r\nTT_cloud <- ggplot (data = TT_top100, aes(label = word)) +\r\n  background_image(smeagol_pic) +\r\n  geom_text_wordcloud(aes(color = n, size = n)) +\r\n  scale_size_area(max_size = 13) +\r\n  scale_color_gradientn(colors = c(\"coral\", \"firebrick2\", \"firebrick3\")) +\r\n  theme_minimal() +\r\n  labs(title = \"Top 100 words used in The Two Towers\")\r\n\r\nTT_cloud\r\n\r\n\r\n\r\n\r\nSummary\r\nI took a .pdf copy of The Two Towers, by J.R.R. Tolken, and used a wordcloud to determine which words were most spoken in the book. I was amazed that I was able to take a .pdf file and convert it into a data frame that I could manipulate. The smaller, lighter colors represent words that are less used and the bigger, darker colors represent more common words. Who would have known the main character’s name is the most common!\r\nCitations:\r\nTolkien, J. R. R. (2005). The two towers. HarperCollins. source: http://old.ahmadtea.ua/userfiles/files/Tolkien/Lord%20Of%20The%20Rings%20-%20Part%202%20-%20The%20Two%20Towers%20By%20J%20R%20R%20Tolkien.pdf\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-03-09-lotr/lotr_files/figure-html5/unnamed-chunk-2-1.png",
    "last_modified": "2021-03-13T10:22:20-08:00",
    "input_file": "lotr.utf8.md"
  }
]
